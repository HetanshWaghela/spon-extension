{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ZQgmg1_jsD",
        "outputId": "282f9666-b739-4ef5-a271-b96d095083fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'spon-extension' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/HetanshWaghela/spon-extension.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpQS81oaANJq",
        "outputId": "5ba2e1b3-ad8e-4b2e-d34c-1400d4543480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/spon-extension\n"
          ]
        }
      ],
      "source": [
        "%cd spon-extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNY_-2N7APOF",
        "outputId": "7289c291-9b11-483a-d31f-248017c2acff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (5.0.0)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.0.0)\n",
            "Requirement already satisfied: accelerate>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (1.12.0)\n",
            "Requirement already satisfied: lm-eval>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.4.10)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: plotly>=5.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 35)) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 36)) (1.16.3)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 37)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 43)) (6.0.3)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 44)) (4.67.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 9)) (26.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 9)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 9)) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 9)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 10)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 10)) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 10)) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 10)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements.txt (line 10)) (0.70.16)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.24.0->-r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: evaluate>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (4.0.0)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (1.2.1)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (2.1.0)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (0.25.0)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (1.1)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.12/dist-packages (from lm-eval>=0.4.0->-r requirements.txt (line 16)) (10.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 27)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 27)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 27)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 27)) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 27)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 27)) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 27)) (2.9.0.post0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=5.15.0->-r requirements.txt (line 29)) (9.1.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 35)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 35)) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 38)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 38)) (2025.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 10)) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.36.0->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.36.0->-r requirements.txt (line 9)) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers>=4.36.0->-r requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->-r requirements.txt (line 27)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.0->-r requirements.txt (line 10)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.0->-r requirements.txt (line 10)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.0->-r requirements.txt (line 10)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.14.0->-r requirements.txt (line 10)) (2026.1.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.0.4->lm-eval>=0.4.0->-r requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge-score>=0.0.4->lm-eval>=0.4.0->-r requirements.txt (line 16)) (3.9.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.0->-r requirements.txt (line 16)) (3.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.0->-r requirements.txt (line 16)) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.0->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.0->-r requirements.txt (line 16)) (6.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 8)) (3.0.3)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines->lm-eval>=0.4.0->-r requirements.txt (line 16)) (25.4.0)\n",
            "Requirement already satisfied: DataProperty<2,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval>=0.4.0->-r requirements.txt (line 16)) (1.1.0)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval>=0.4.0->-r requirements.txt (line 16)) (1.1.4)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval>=0.4.0->-r requirements.txt (line 16)) (3.3.1)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval>=0.4.0->-r requirements.txt (line 16)) (1.3.4)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.12/dist-packages (from pytablewriter->lm-eval>=0.4.0->-r requirements.txt (line 16)) (0.1.7)\n",
            "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval>=0.4.0->-r requirements.txt (line 16)) (1.3.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers>=4.36.0->-r requirements.txt (line 9)) (8.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 10)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 10)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 10)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 10)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements.txt (line 10)) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.36.0->-r requirements.txt (line 9)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.36.0->-r requirements.txt (line 9)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers>=4.36.0->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval>=0.4.0->-r requirements.txt (line 16)) (5.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtkofRN3AVlC"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"your_huggingface_token_here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPM3W6soAaZb",
        "outputId": "edc15f1c-347d-401d-d673-a955098f6df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-08 06:55:28 | INFO | __main__ | Using device: cuda\n",
            "2026-02-08 06:55:28 | INFO | src.model_provider | Model provider requested=auto effective=huggingface ollama_available=False ollama_model=llama3.2:1b\n",
            "2026-02-08 06:55:28 | INFO | __main__ | ======================================================================\n",
            "2026-02-08 06:55:28 | INFO | __main__ | SPON Allocation Sweep Experiment\n",
            "2026-02-08 06:55:28 | INFO | __main__ | ======================================================================\n",
            "2026-02-08 06:55:28 | INFO | __main__ | Model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 06:55:28 | INFO | __main__ | Configurations: ['BASELINE-TEAL', 'UNIF-ALL', 'TOP-50', 'TOP-75', 'BOTTOM-50', 'ATTN-ONLY']\n",
            "2026-02-08 06:55:28 | INFO | __main__ | Sparsity levels: [0.5, 0.6]\n",
            "2026-02-08 06:55:28 | INFO | __main__ | Output: results\n",
            "2026-02-08 06:55:28 | INFO | __main__ | Default sparse modules: ['down_proj']\n",
            "2026-02-08 06:55:28 | INFO | __main__ | ======================================================================\n",
            "2026-02-08 06:55:28 | INFO | src.result_manager | Initialized experiment: allocation_sweep\n",
            "2026-02-08 06:55:28 | INFO | src.result_manager | Started run: run_20260208_065528\n",
            "2026-02-08 06:55:28 | INFO | __main__ | Loading tokenizer...\n",
            "2026-02-08 06:55:32 | INFO | numexpr.utils | NumExpr defaulting to 12 threads.\n",
            "2026-02-08 06:55:33 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:33 | INFO | httpx | HTTP Request: GET https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "config.json: 100% 843/843 [00:00<00:00, 3.59MB/s]\n",
            "2026-02-08 06:55:33 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:34 | INFO | httpx | HTTP Request: GET https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "tokenizer_config.json: 100% 50.5k/50.5k [00:00<00:00, 1.16MB/s]\n",
            "2026-02-08 06:55:34 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:34 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.2-1B/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:34 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.2-1B/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:35 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:35 | INFO | httpx | HTTP Request: GET https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer.json \"HTTP/1.1 200 OK\"\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:01<00:00, 7.16MB/s]\n",
            "2026-02-08 06:55:37 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer.model \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:37 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/added_tokens.json \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:37 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:37 | INFO | httpx | HTTP Request: GET https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/special_tokens_map.json \"HTTP/1.1 200 OK\"\n",
            "special_tokens_map.json: 100% 301/301 [00:00<00:00, 1.50MB/s]\n",
            "2026-02-08 06:55:38 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/chat_template.jinja \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:39 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.2-1B \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:39 | INFO | __main__ | Creating calibration dataloaders...\n",
            "2026-02-08 06:55:39 | INFO | datasets | TensorFlow version 2.19.0 available.\n",
            "2026-02-08 06:55:39 | INFO | datasets | JAX version 0.7.2 available.\n",
            "2026-02-08 06:55:40 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:41 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:41 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/Salesforce/wikitext/b08601e04326c79dfdd32d625aee71d232d685c3/README.md \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:41 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/resolve-cache/datasets/Salesforce/wikitext/b08601e04326c79dfdd32d625aee71d232d685c3/README.md \"HTTP/1.1 200 OK\"\n",
            "README.md: 10.5kB [00:00, 5.84MB/s]\n",
            "2026-02-08 06:55:41 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext.py \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:42 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:42 | INFO | httpx | HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/wikitext/wikitext.py \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:43 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/wikitext/revision/b08601e04326c79dfdd32d625aee71d232d685c3 \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:43 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/Salesforce/wikitext/revision/b08601e04326c79dfdd32d625aee71d232d685c3 \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:43 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/.huggingface.yaml \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:43 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:44 | INFO | httpx | HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=wikitext \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:44 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/wikitext/tree/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1?recursive=true&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:44 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/Salesforce/wikitext/tree/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:44 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/wikitext/tree/b08601e04326c79dfdd32d625aee71d232d685c3?recursive=false&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:45 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/Salesforce/wikitext/tree/b08601e04326c79dfdd32d625aee71d232d685c3?recursive=false&expand=false \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:45 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/dataset_infos.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:45 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:45 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/test-00000-of-00001.parquet \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:46 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/test-00000-of-00001.parquet \"HTTP/1.1 302 Found\"\n",
            "2026-02-08 06:55:46 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/datasets/Salesforce/wikitext/xet-read-token/b08601e04326c79dfdd32d625aee71d232d685c3 \"HTTP/1.1 200 OK\"\n",
            "wikitext-103-raw-v1/test-00000-of-00001.(…): 100% 733k/733k [00:01<00:00, 598kB/s]  \n",
            "2026-02-08 06:55:47 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/train-00000-of-00002.parquet \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:48 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/train-00000-of-00002.parquet \"HTTP/1.1 302 Found\"\n",
            "wikitext-103-raw-v1/train-00000-of-00002(…): 100% 157M/157M [00:02<00:00, 71.7MB/s]\n",
            "2026-02-08 06:55:50 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/train-00001-of-00002.parquet \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:50 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/train-00001-of-00002.parquet \"HTTP/1.1 302 Found\"\n",
            "wikitext-103-raw-v1/train-00001-of-00002(…): 100% 157M/157M [00:01<00:00, 110MB/s]  \n",
            "2026-02-08 06:55:52 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/validation-00000-of-00001.parquet \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:52 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext-103-raw-v1/validation-00000-of-00001.parquet \"HTTP/1.1 302 Found\"\n",
            "wikitext-103-raw-v1/validation-00000-of-(…): 100% 657k/657k [00:00<00:00, 1.18MB/s]\n",
            "Generating test split: 100% 4358/4358 [00:00<00:00, 140119.87 examples/s]\n",
            "Generating train split: 100% 1801350/1801350 [00:02<00:00, 900478.67 examples/s]\n",
            "Generating validation split: 100% 3760/3760 [00:00<00:00, 635756.79 examples/s]\n",
            "2026-02-08 06:55:57 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:57 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/main/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:57 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/api/resolve-cache/datasets/Salesforce/wikitext/b08601e04326c79dfdd32d625aee71d232d685c3/README.md \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:58 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext.py \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:58 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/wikitext.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:59 | INFO | httpx | HTTP Request: HEAD https://s3.amazonaws.com/datasets.huggingface.co/datasets/datasets/wikitext/wikitext.py \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:55:59 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/.huggingface.yaml \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:55:59 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/.huggingface.yaml \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:55:59 | INFO | httpx | HTTP Request: GET https://datasets-server.huggingface.co/info?dataset=wikitext \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:56:00 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/dataset_infos.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "2026-02-08 06:56:00 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/datasets/Salesforce/wikitext/resolve/b08601e04326c79dfdd32d625aee71d232d685c3/dataset_infos.json \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:56:01 | INFO | __main__ | Computing dense baseline...\n",
            "2026-02-08 06:56:01 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 06:56:01 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:01 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-02-08 06:56:02 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:03 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n",
            "2026-02-08 06:56:03 | INFO | httpx | HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.2-1B/xet-read-token/4e20de362430cd3b72f300e6b0f18e50e7166e08 \"HTTP/1.1 200 OK\"\n",
            "model.safetensors: 100% 2.47G/2.47G [00:03<00:00, 815MB/s] \n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1225.68it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 06:56:07 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:08 | INFO | httpx | HTTP Request: GET https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "generation_config.json: 100% 185/185 [00:00<00:00, 952kB/s]\n",
            "2026-02-08 06:56:08 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:56:09 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 36.34it/s]\n",
            "2026-02-08 06:56:12 | INFO | __main__ | Dense baseline PPL: 21.64\n",
            "2026-02-08 06:56:12 | INFO | __main__ | \n",
            "######################################################################\n",
            "2026-02-08 06:56:12 | INFO | __main__ | # Sparsity Level: 50%\n",
            "2026-02-08 06:56:12 | INFO | __main__ | ######################################################################\n",
            "\n",
            "2026-02-08 06:56:12 | INFO | __main__ | Computing sparse baseline (TEAL-only) for sparsity=0.5 modules=['down_proj']\n",
            "2026-02-08 06:56:12 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 06:56:12 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:13 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1866.92it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 06:56:13 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:13 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:56:14 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 33.91it/s]\n",
            "2026-02-08 06:56:18 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 06:56:18 | INFO | __main__ | Configuration: BASELINE-TEAL @ 50% sparsity\n",
            "2026-02-08 06:56:18 | INFO | __main__ | Layers: []\n",
            "2026-02-08 06:56:18 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 06:56:18 | INFO | __main__ | ============================================================\n",
            "2026-02-08 06:56:18 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 06:56:18 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:18 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1627.54it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 06:56:19 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:19 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:56:20 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 06:56:20 | INFO | __main__ | Baseline config - no SPON training needed\n",
            "2026-02-08 06:56:20 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.34it/s]\n",
            "2026-02-08 06:56:24 | INFO | __main__ | Perplexity: 22.60\n",
            "2026-02-08 06:56:24 | INFO | src.result_manager | Logged result: BASELINE-TEAL @ 50% sparsity -> PPL=22.60\n",
            "2026-02-08 06:56:24 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 06:56:24 | INFO | __main__ | Configuration: UNIF-ALL @ 50% sparsity\n",
            "2026-02-08 06:56:24 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "2026-02-08 06:56:24 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 06:56:24 | INFO | __main__ | ============================================================\n",
            "2026-02-08 06:56:24 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 06:56:24 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:24 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1215.07it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 06:56:24 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 06:56:25 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 06:56:25 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_0_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_1_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_2_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_3_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_4_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_5_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_6_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_7_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_8_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_9_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_10_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_11_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_12_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_13_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_14_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Registered SPON bias: layer_15_down_proj with dim 2048\n",
            "2026-02-08 06:56:25 | INFO | src.spon_trainer | Total SPON parameters: 32768\n",
            "2026-02-08 06:56:25 | INFO | __main__ | Training 32,768 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 11.69it/s, loss=0.0439]\n",
            "2026-02-08 06:56:47 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0439\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 11.87it/s, loss=0.0430]\n",
            "2026-02-08 06:57:09 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0429\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 11.88it/s, loss=0.0426]\n",
            "2026-02-08 06:57:30 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0426\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 11.96it/s, loss=0.0422]\n",
            "2026-02-08 06:57:52 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0422\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0420]\n",
            "2026-02-08 06:58:13 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0420\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0419]\n",
            "2026-02-08 06:58:35 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0419\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 11.95it/s, loss=0.0417]\n",
            "2026-02-08 06:58:56 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0416\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 11.96it/s, loss=0.0416]\n",
            "2026-02-08 06:59:17 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0416\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0415]\n",
            "2026-02-08 06:59:39 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0415\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0413]\n",
            "2026-02-08 07:00:00 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0413\n",
            "2026-02-08 07:00:00 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_UNIF-ALL_s0.50.pt\n",
            "2026-02-08 07:00:00 | INFO | __main__ | Training complete. Final loss: 0.0421\n",
            "2026-02-08 07:00:00 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.50it/s]\n",
            "2026-02-08 07:00:04 | INFO | __main__ | Perplexity: 22.38\n",
            "2026-02-08 07:00:04 | INFO | src.result_manager | Logged result: UNIF-ALL @ 50% sparsity -> PPL=22.38\n",
            "2026-02-08 07:00:04 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:00:04 | INFO | __main__ | Configuration: TOP-50 @ 50% sparsity\n",
            "2026-02-08 07:00:04 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "2026-02-08 07:00:04 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:00:04 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:00:04 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:00:04 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:00:05 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1221.21it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:00:05 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:00:05 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:00:06 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_0_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_1_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_2_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_3_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_4_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_5_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_6_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Registered SPON bias: layer_7_down_proj with dim 2048\n",
            "2026-02-08 07:00:06 | INFO | src.spon_trainer | Total SPON parameters: 16384\n",
            "2026-02-08 07:00:06 | INFO | __main__ | Training 16,384 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 12.01it/s, loss=0.0441]\n",
            "2026-02-08 07:00:27 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0441\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0433]\n",
            "2026-02-08 07:00:49 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0432\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0431]\n",
            "2026-02-08 07:01:10 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0431\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0428]\n",
            "2026-02-08 07:01:32 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0428\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 11.96it/s, loss=0.0426]\n",
            "2026-02-08 07:01:53 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0426\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0425]\n",
            "2026-02-08 07:02:14 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0424\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 11.96it/s, loss=0.0424]\n",
            "2026-02-08 07:02:36 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0424\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0422]\n",
            "2026-02-08 07:02:57 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0422\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 12.01it/s, loss=0.0423]\n",
            "2026-02-08 07:03:18 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0422\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 12.00it/s, loss=0.0421]\n",
            "2026-02-08 07:03:40 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0421\n",
            "2026-02-08 07:03:40 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-50_s0.50.pt\n",
            "2026-02-08 07:03:40 | INFO | __main__ | Training complete. Final loss: 0.0427\n",
            "2026-02-08 07:03:40 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.61it/s]\n",
            "2026-02-08 07:03:44 | INFO | __main__ | Perplexity: 22.42\n",
            "2026-02-08 07:03:44 | INFO | src.result_manager | Logged result: TOP-50 @ 50% sparsity -> PPL=22.42\n",
            "2026-02-08 07:03:44 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:03:44 | INFO | __main__ | Configuration: TOP-75 @ 50% sparsity\n",
            "2026-02-08 07:03:44 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "2026-02-08 07:03:44 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:03:44 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:03:44 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:03:44 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:03:45 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1349.16it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:03:45 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:03:45 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:03:46 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_0_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_1_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_2_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_3_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_4_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_5_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_6_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_7_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_8_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_9_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_10_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Registered SPON bias: layer_11_down_proj with dim 2048\n",
            "2026-02-08 07:03:46 | INFO | src.spon_trainer | Total SPON parameters: 24576\n",
            "2026-02-08 07:03:46 | INFO | __main__ | Training 24,576 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 11.93it/s, loss=0.0439]\n",
            "2026-02-08 07:04:07 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0439\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0431]\n",
            "2026-02-08 07:04:29 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0431\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0425]\n",
            "2026-02-08 07:04:50 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0425\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0424]\n",
            "2026-02-08 07:05:12 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0423\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0421]\n",
            "2026-02-08 07:05:33 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0421\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 12.00it/s, loss=0.0419]\n",
            "2026-02-08 07:05:54 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0419\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 12.00it/s, loss=0.0418]\n",
            "2026-02-08 07:06:16 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0418\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 11.96it/s, loss=0.0416]\n",
            "2026-02-08 07:06:37 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0417\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 12.00it/s, loss=0.0416]\n",
            "2026-02-08 07:06:58 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0415\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0415]\n",
            "2026-02-08 07:07:20 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0415\n",
            "2026-02-08 07:07:21 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-75_s0.50.pt\n",
            "2026-02-08 07:07:21 | INFO | __main__ | Training complete. Final loss: 0.0422\n",
            "2026-02-08 07:07:21 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.53it/s]\n",
            "2026-02-08 07:07:24 | INFO | __main__ | Perplexity: 22.41\n",
            "2026-02-08 07:07:24 | INFO | src.result_manager | Logged result: TOP-75 @ 50% sparsity -> PPL=22.41\n",
            "2026-02-08 07:07:24 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:07:24 | INFO | __main__ | Configuration: BOTTOM-50 @ 50% sparsity\n",
            "2026-02-08 07:07:24 | INFO | __main__ | Layers: [8, 9, 10, 11, 12, 13, 14, 15]\n",
            "2026-02-08 07:07:24 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:07:24 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:07:24 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:07:25 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:07:25 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1381.55it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:07:25 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:07:25 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:07:26 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_8_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_9_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_10_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_11_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_12_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_13_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_14_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Registered SPON bias: layer_15_down_proj with dim 2048\n",
            "2026-02-08 07:07:26 | INFO | src.spon_trainer | Total SPON parameters: 16384\n",
            "2026-02-08 07:07:26 | INFO | __main__ | Training 16,384 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:18<00:00, 13.73it/s, loss=0.0444]\n",
            "2026-02-08 07:07:45 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0444\n",
            "Epoch 2/10: 100% 256/256 [00:18<00:00, 13.71it/s, loss=0.0440]\n",
            "2026-02-08 07:08:04 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0439\n",
            "Epoch 3/10: 100% 256/256 [00:18<00:00, 13.75it/s, loss=0.0436]\n",
            "2026-02-08 07:08:22 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0436\n",
            "Epoch 4/10: 100% 256/256 [00:18<00:00, 13.77it/s, loss=0.0435]\n",
            "2026-02-08 07:08:41 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0434\n",
            "Epoch 5/10: 100% 256/256 [00:18<00:00, 13.77it/s, loss=0.0433]\n",
            "2026-02-08 07:08:59 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0433\n",
            "Epoch 6/10: 100% 256/256 [00:18<00:00, 13.75it/s, loss=0.0432]\n",
            "2026-02-08 07:09:18 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0432\n",
            "Epoch 7/10: 100% 256/256 [00:18<00:00, 13.69it/s, loss=0.0431]\n",
            "2026-02-08 07:09:37 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0431\n",
            "Epoch 8/10: 100% 256/256 [00:18<00:00, 13.74it/s, loss=0.0431]\n",
            "2026-02-08 07:09:55 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0431\n",
            "Epoch 9/10: 100% 256/256 [00:18<00:00, 13.76it/s, loss=0.0430]\n",
            "2026-02-08 07:10:14 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0430\n",
            "Epoch 10/10: 100% 256/256 [00:18<00:00, 13.73it/s, loss=0.0429]\n",
            "2026-02-08 07:10:33 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0429\n",
            "2026-02-08 07:10:34 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_BOTTOM-50_s0.50.pt\n",
            "2026-02-08 07:10:34 | INFO | __main__ | Training complete. Final loss: 0.0434\n",
            "2026-02-08 07:10:34 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.60it/s]\n",
            "2026-02-08 07:10:37 | INFO | __main__ | Perplexity: 22.47\n",
            "2026-02-08 07:10:37 | INFO | src.result_manager | Logged result: BOTTOM-50 @ 50% sparsity -> PPL=22.47\n",
            "2026-02-08 07:10:37 | INFO | __main__ | Computing sparse baseline (TEAL-only) for sparsity=0.5 modules=['o_proj']\n",
            "2026-02-08 07:10:37 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:10:38 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:10:38 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1504.09it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:10:38 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:10:39 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:10:39 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 40.15it/s]\n",
            "2026-02-08 07:10:42 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:10:42 | INFO | __main__ | Configuration: ATTN-ONLY @ 50% sparsity\n",
            "2026-02-08 07:10:42 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "2026-02-08 07:10:42 | INFO | __main__ | Modules: ['o_proj']\n",
            "2026-02-08 07:10:42 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:10:42 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:10:43 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:10:43 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 2341.98it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:10:43 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:10:44 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:10:44 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_0_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_1_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_2_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_3_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_4_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_5_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_6_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_7_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_8_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_9_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_10_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_11_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_12_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_13_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_14_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Registered SPON bias: layer_15_o_proj with dim 2048\n",
            "2026-02-08 07:10:44 | INFO | src.spon_trainer | Total SPON parameters: 32768\n",
            "2026-02-08 07:10:44 | INFO | __main__ | Training 32,768 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 11.91it/s, loss=0.0188]\n",
            "2026-02-08 07:11:06 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0188\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 12.00it/s, loss=0.0178]\n",
            "2026-02-08 07:11:27 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0178\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 12.00it/s, loss=0.0175]\n",
            "2026-02-08 07:11:48 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0175\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 12.02it/s, loss=0.0172]\n",
            "2026-02-08 07:12:10 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0173\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 12.05it/s, loss=0.0171]\n",
            "2026-02-08 07:12:31 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0171\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 11.99it/s, loss=0.0170]\n",
            "2026-02-08 07:12:52 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0170\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 12.03it/s, loss=0.0169]\n",
            "2026-02-08 07:13:14 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0169\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 12.03it/s, loss=0.0168]\n",
            "2026-02-08 07:13:35 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0168\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 12.01it/s, loss=0.0167]\n",
            "2026-02-08 07:13:56 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0167\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0167]\n",
            "2026-02-08 07:14:18 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0167\n",
            "2026-02-08 07:14:19 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_ATTN-ONLY_s0.50.pt\n",
            "2026-02-08 07:14:19 | INFO | __main__ | Training complete. Final loss: 0.0173\n",
            "2026-02-08 07:14:19 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 39.04it/s]\n",
            "2026-02-08 07:14:22 | INFO | __main__ | Perplexity: 21.75\n",
            "2026-02-08 07:14:22 | INFO | src.result_manager | Logged result: ATTN-ONLY @ 50% sparsity -> PPL=21.75\n",
            "2026-02-08 07:14:22 | INFO | __main__ | \n",
            "######################################################################\n",
            "2026-02-08 07:14:22 | INFO | __main__ | # Sparsity Level: 60%\n",
            "2026-02-08 07:14:22 | INFO | __main__ | ######################################################################\n",
            "\n",
            "2026-02-08 07:14:22 | INFO | __main__ | Computing sparse baseline (TEAL-only) for sparsity=0.6 modules=['down_proj']\n",
            "2026-02-08 07:14:22 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:14:23 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:14:23 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1474.29it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:14:23 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:14:23 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:14:24 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.78it/s]\n",
            "2026-02-08 07:14:28 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:14:28 | INFO | __main__ | Configuration: BASELINE-TEAL @ 60% sparsity\n",
            "2026-02-08 07:14:28 | INFO | __main__ | Layers: []\n",
            "2026-02-08 07:14:28 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:14:28 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:14:28 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:14:28 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:14:28 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1327.95it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:14:29 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:14:29 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:14:30 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:14:30 | INFO | __main__ | Baseline config - no SPON training needed\n",
            "2026-02-08 07:14:30 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.43it/s]\n",
            "2026-02-08 07:14:33 | INFO | __main__ | Perplexity: 23.93\n",
            "2026-02-08 07:14:33 | INFO | src.result_manager | Logged result: BASELINE-TEAL @ 60% sparsity -> PPL=23.93\n",
            "2026-02-08 07:14:33 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:14:33 | INFO | __main__ | Configuration: UNIF-ALL @ 60% sparsity\n",
            "2026-02-08 07:14:33 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "2026-02-08 07:14:33 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:14:33 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:14:33 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:14:34 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:14:34 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 3756.49it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:14:34 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:14:35 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:14:35 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_0_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_1_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_2_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_3_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_4_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_5_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_6_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_7_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_8_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_9_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_10_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_11_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_12_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_13_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_14_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Registered SPON bias: layer_15_down_proj with dim 2048\n",
            "2026-02-08 07:14:35 | INFO | src.spon_trainer | Total SPON parameters: 32768\n",
            "2026-02-08 07:14:35 | INFO | __main__ | Training 32,768 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 11.86it/s, loss=0.0977]\n",
            "2026-02-08 07:14:57 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0977\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 11.91it/s, loss=0.0944]\n",
            "2026-02-08 07:15:19 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0943\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 11.91it/s, loss=0.0929]\n",
            "2026-02-08 07:15:40 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0930\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 11.87it/s, loss=0.0922]\n",
            "2026-02-08 07:16:02 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0921\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 11.92it/s, loss=0.0914]\n",
            "2026-02-08 07:16:23 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0914\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 11.88it/s, loss=0.0910]\n",
            "2026-02-08 07:16:45 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0910\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0909]\n",
            "2026-02-08 07:17:06 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0908\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0903]\n",
            "2026-02-08 07:17:27 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0903\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0901]\n",
            "2026-02-08 07:17:49 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0900\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 11.89it/s, loss=0.0901]\n",
            "2026-02-08 07:18:10 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0901\n",
            "2026-02-08 07:18:12 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_UNIF-ALL_s0.60.pt\n",
            "2026-02-08 07:18:12 | INFO | __main__ | Training complete. Final loss: 0.0921\n",
            "2026-02-08 07:18:12 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.40it/s]\n",
            "2026-02-08 07:18:16 | INFO | __main__ | Perplexity: 23.40\n",
            "2026-02-08 07:18:16 | INFO | src.result_manager | Logged result: UNIF-ALL @ 60% sparsity -> PPL=23.40\n",
            "2026-02-08 07:18:16 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:18:16 | INFO | __main__ | Configuration: TOP-50 @ 60% sparsity\n",
            "2026-02-08 07:18:16 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "2026-02-08 07:18:16 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:18:16 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:18:16 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:18:16 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:18:16 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1183.06it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:18:17 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:18:17 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:18:18 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_0_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_1_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_2_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_3_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_4_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_5_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_6_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Registered SPON bias: layer_7_down_proj with dim 2048\n",
            "2026-02-08 07:18:18 | INFO | src.spon_trainer | Total SPON parameters: 16384\n",
            "2026-02-08 07:18:18 | INFO | __main__ | Training 16,384 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 11.96it/s, loss=0.0984]\n",
            "2026-02-08 07:18:39 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0984\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0959]\n",
            "2026-02-08 07:19:01 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0958\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 11.89it/s, loss=0.0948]\n",
            "2026-02-08 07:19:22 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0948\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 11.93it/s, loss=0.0940]\n",
            "2026-02-08 07:19:44 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0939\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 11.78it/s, loss=0.0933]\n",
            "2026-02-08 07:20:05 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0933\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 11.84it/s, loss=0.0931]\n",
            "2026-02-08 07:20:27 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0931\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 11.89it/s, loss=0.0926]\n",
            "2026-02-08 07:20:48 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0925\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 11.90it/s, loss=0.0923]\n",
            "2026-02-08 07:21:10 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0923\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 11.92it/s, loss=0.0923]\n",
            "2026-02-08 07:21:31 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0922\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0917]\n",
            "2026-02-08 07:21:53 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0917\n",
            "2026-02-08 07:21:55 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-50_s0.60.pt\n",
            "2026-02-08 07:21:55 | INFO | __main__ | Training complete. Final loss: 0.0938\n",
            "2026-02-08 07:21:55 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.09it/s]\n",
            "2026-02-08 07:21:59 | INFO | __main__ | Perplexity: 23.44\n",
            "2026-02-08 07:21:59 | INFO | src.result_manager | Logged result: TOP-50 @ 60% sparsity -> PPL=23.44\n",
            "2026-02-08 07:21:59 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:21:59 | INFO | __main__ | Configuration: TOP-75 @ 60% sparsity\n",
            "2026-02-08 07:21:59 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "2026-02-08 07:21:59 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:21:59 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:21:59 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:21:59 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:21:59 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1507.06it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:21:59 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:22:00 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:22:00 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_0_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_1_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_2_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_3_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_4_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_5_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_6_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_7_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_8_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_9_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_10_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Registered SPON bias: layer_11_down_proj with dim 2048\n",
            "2026-02-08 07:22:00 | INFO | src.spon_trainer | Total SPON parameters: 24576\n",
            "2026-02-08 07:22:00 | INFO | __main__ | Training 24,576 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 11.90it/s, loss=0.0974]\n",
            "2026-02-08 07:22:22 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0974\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0946]\n",
            "2026-02-08 07:22:43 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0945\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 11.98it/s, loss=0.0933]\n",
            "2026-02-08 07:23:05 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0933\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0926]\n",
            "2026-02-08 07:23:26 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0925\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 11.92it/s, loss=0.0919]\n",
            "2026-02-08 07:23:48 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0919\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 11.88it/s, loss=0.0915]\n",
            "2026-02-08 07:24:09 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0915\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 11.97it/s, loss=0.0911]\n",
            "2026-02-08 07:24:31 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0911\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 11.95it/s, loss=0.0909]\n",
            "2026-02-08 07:24:52 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0909\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 11.95it/s, loss=0.0905]\n",
            "2026-02-08 07:25:13 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0904\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 11.94it/s, loss=0.0902]\n",
            "2026-02-08 07:25:35 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0902\n",
            "2026-02-08 07:25:37 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-75_s0.60.pt\n",
            "2026-02-08 07:25:37 | INFO | __main__ | Training complete. Final loss: 0.0924\n",
            "2026-02-08 07:25:37 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.12it/s]\n",
            "2026-02-08 07:25:41 | INFO | __main__ | Perplexity: 23.46\n",
            "2026-02-08 07:25:41 | INFO | src.result_manager | Logged result: TOP-75 @ 60% sparsity -> PPL=23.46\n",
            "2026-02-08 07:25:41 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:25:41 | INFO | __main__ | Configuration: BOTTOM-50 @ 60% sparsity\n",
            "2026-02-08 07:25:41 | INFO | __main__ | Layers: [8, 9, 10, 11, 12, 13, 14, 15]\n",
            "2026-02-08 07:25:41 | INFO | __main__ | Modules: ['down_proj']\n",
            "2026-02-08 07:25:41 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:25:41 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:25:41 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:25:41 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 2544.55it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:25:42 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:25:42 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:25:43 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_8_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_9_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_10_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_11_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_12_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_13_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_14_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Registered SPON bias: layer_15_down_proj with dim 2048\n",
            "2026-02-08 07:25:43 | INFO | src.spon_trainer | Total SPON parameters: 16384\n",
            "2026-02-08 07:25:43 | INFO | __main__ | Training 16,384 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:18<00:00, 13.65it/s, loss=0.0999]\n",
            "2026-02-08 07:26:01 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0998\n",
            "Epoch 2/10: 100% 256/256 [00:18<00:00, 13.68it/s, loss=0.0979]\n",
            "2026-02-08 07:26:20 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0978\n",
            "Epoch 3/10: 100% 256/256 [00:18<00:00, 13.68it/s, loss=0.0968]\n",
            "2026-02-08 07:26:39 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0969\n",
            "Epoch 4/10: 100% 256/256 [00:18<00:00, 13.67it/s, loss=0.0965]\n",
            "2026-02-08 07:26:58 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0964\n",
            "Epoch 5/10: 100% 256/256 [00:18<00:00, 13.65it/s, loss=0.0959]\n",
            "2026-02-08 07:27:16 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0959\n",
            "Epoch 6/10: 100% 256/256 [00:18<00:00, 13.61it/s, loss=0.0956]\n",
            "2026-02-08 07:27:35 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0956\n",
            "Epoch 7/10: 100% 256/256 [00:18<00:00, 13.67it/s, loss=0.0955]\n",
            "2026-02-08 07:27:54 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0954\n",
            "Epoch 8/10: 100% 256/256 [00:18<00:00, 13.61it/s, loss=0.0951]\n",
            "2026-02-08 07:28:13 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0952\n",
            "Epoch 9/10: 100% 256/256 [00:18<00:00, 13.69it/s, loss=0.0951]\n",
            "2026-02-08 07:28:31 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0950\n",
            "Epoch 10/10: 100% 256/256 [00:18<00:00, 13.65it/s, loss=0.0949]\n",
            "2026-02-08 07:28:50 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0949\n",
            "2026-02-08 07:28:53 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_BOTTOM-50_s0.60.pt\n",
            "2026-02-08 07:28:53 | INFO | __main__ | Training complete. Final loss: 0.0963\n",
            "2026-02-08 07:28:53 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 34.26it/s]\n",
            "2026-02-08 07:28:57 | INFO | __main__ | Perplexity: 23.62\n",
            "2026-02-08 07:28:57 | INFO | src.result_manager | Logged result: BOTTOM-50 @ 60% sparsity -> PPL=23.62\n",
            "2026-02-08 07:28:57 | INFO | __main__ | Computing sparse baseline (TEAL-only) for sparsity=0.6 modules=['o_proj']\n",
            "2026-02-08 07:28:57 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:28:57 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:28:57 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1820.17it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:28:57 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:28:58 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:28:58 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 39.85it/s]\n",
            "2026-02-08 07:29:02 | INFO | __main__ | \n",
            "============================================================\n",
            "2026-02-08 07:29:02 | INFO | __main__ | Configuration: ATTN-ONLY @ 60% sparsity\n",
            "2026-02-08 07:29:02 | INFO | __main__ | Layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "2026-02-08 07:29:02 | INFO | __main__ | Modules: ['o_proj']\n",
            "2026-02-08 07:29:02 | INFO | __main__ | ============================================================\n",
            "2026-02-08 07:29:02 | INFO | __main__ | Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:29:02 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:29:02 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 3282.33it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:29:02 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:29:03 | INFO | httpx | HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:29:03 | INFO | __main__ | Model loaded: 16 layers, 1.24B parameters\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_0_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_1_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_2_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_3_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_4_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_5_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_6_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_7_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_8_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_9_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_10_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_11_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_12_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_13_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_14_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Registered SPON bias: layer_15_o_proj with dim 2048\n",
            "2026-02-08 07:29:03 | INFO | src.spon_trainer | Total SPON parameters: 32768\n",
            "2026-02-08 07:29:03 | INFO | __main__ | Training 32,768 SPON parameters...\n",
            "Epoch 1/10: 100% 256/256 [00:21<00:00, 11.95it/s, loss=0.0367]\n",
            "2026-02-08 07:29:25 | INFO | src.spon_trainer | Epoch 1 complete. Avg loss: 0.0366\n",
            "Epoch 2/10: 100% 256/256 [00:21<00:00, 12.03it/s, loss=0.0344]\n",
            "2026-02-08 07:29:46 | INFO | src.spon_trainer | Epoch 2 complete. Avg loss: 0.0344\n",
            "Epoch 3/10: 100% 256/256 [00:21<00:00, 11.99it/s, loss=0.0337]\n",
            "2026-02-08 07:30:08 | INFO | src.spon_trainer | Epoch 3 complete. Avg loss: 0.0336\n",
            "Epoch 4/10: 100% 256/256 [00:21<00:00, 11.99it/s, loss=0.0332]\n",
            "2026-02-08 07:30:29 | INFO | src.spon_trainer | Epoch 4 complete. Avg loss: 0.0332\n",
            "Epoch 5/10: 100% 256/256 [00:21<00:00, 12.07it/s, loss=0.0328]\n",
            "2026-02-08 07:30:50 | INFO | src.spon_trainer | Epoch 5 complete. Avg loss: 0.0328\n",
            "Epoch 6/10: 100% 256/256 [00:21<00:00, 12.08it/s, loss=0.0325]\n",
            "2026-02-08 07:31:11 | INFO | src.spon_trainer | Epoch 6 complete. Avg loss: 0.0325\n",
            "Epoch 7/10: 100% 256/256 [00:21<00:00, 11.99it/s, loss=0.0323]\n",
            "2026-02-08 07:31:33 | INFO | src.spon_trainer | Epoch 7 complete. Avg loss: 0.0323\n",
            "Epoch 8/10: 100% 256/256 [00:21<00:00, 12.04it/s, loss=0.0321]\n",
            "2026-02-08 07:31:54 | INFO | src.spon_trainer | Epoch 8 complete. Avg loss: 0.0321\n",
            "Epoch 9/10: 100% 256/256 [00:21<00:00, 12.03it/s, loss=0.0319]\n",
            "2026-02-08 07:32:15 | INFO | src.spon_trainer | Epoch 9 complete. Avg loss: 0.0319\n",
            "Epoch 10/10: 100% 256/256 [00:21<00:00, 11.99it/s, loss=0.0318]\n",
            "2026-02-08 07:32:37 | INFO | src.spon_trainer | Epoch 10 complete. Avg loss: 0.0318\n",
            "2026-02-08 07:32:39 | INFO | src.result_manager | Saved checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_ATTN-ONLY_s0.60.pt\n",
            "2026-02-08 07:32:39 | INFO | __main__ | Training complete. Final loss: 0.0331\n",
            "2026-02-08 07:32:39 | INFO | __main__ | Evaluating...\n",
            "Computing perplexity: 100% 128/128 [00:03<00:00, 38.76it/s]\n",
            "2026-02-08 07:32:43 | INFO | __main__ | Perplexity: 21.89\n",
            "2026-02-08 07:32:43 | INFO | src.result_manager | Logged result: ATTN-ONLY @ 60% sparsity -> PPL=21.89\n",
            "2026-02-08 07:32:43 | INFO | src.result_manager | Finished run: run_20260208_065528 (duration: 2235.1s)\n",
            "2026-02-08 07:32:43 | WARNING | src.result_manager | Run not found or incomplete: run_20260208_064842\n",
            "2026-02-08 07:32:43 | WARNING | src.result_manager | Run not found or incomplete: run_20260208_065455\n",
            "2026-02-08 07:32:43 | WARNING | src.result_manager | Run not found or incomplete: run_20260208_065131\n",
            "2026-02-08 07:32:43 | WARNING | src.result_manager | Run not found or incomplete: run_20260208_065236\n",
            "2026-02-08 07:32:43 | WARNING | src.result_manager | Run not found or incomplete: run_20260208_065313\n",
            "2026-02-08 07:32:43 | INFO | src.result_manager | Aggregated 12 results from 6 runs\n",
            "2026-02-08 07:32:43 | INFO | src.result_manager | Exported LaTeX table: results/allocation_sweep/aggregated/latex_tables/allocation_results.tex\n",
            "2026-02-08 07:32:43 | INFO | __main__ | \n",
            "======================================================================\n",
            "2026-02-08 07:32:43 | INFO | __main__ | EXPERIMENT COMPLETE\n",
            "2026-02-08 07:32:43 | INFO | __main__ | ======================================================================\n",
            "2026-02-08 07:32:43 | INFO | __main__ | Total configurations tested: 12\n",
            "2026-02-08 07:32:43 | INFO | __main__ | Best config: ATTN-ONLY (PPL=21.75)\n",
            "2026-02-08 07:32:43 | INFO | __main__ | Pareto-optimal: ['BASELINE-TEAL', 'TOP-50', 'TOP-75', 'UNIF-ALL', 'ATTN-ONLY']\n",
            "2026-02-08 07:32:43 | INFO | __main__ | Results saved to: results/allocation_sweep/runs/run_20260208_065528\n",
            "2026-02-08 07:32:43 | INFO | __main__ | ======================================================================\n"
          ]
        }
      ],
      "source": [
        "!python experiments/exp1_allocation/run_allocation_sweep.py \\\n",
        "    --model meta-llama/Llama-3.2-1B \\\n",
        "    --configs BASELINE-TEAL UNIF-ALL TOP-50 TOP-75 BOTTOM-50 ATTN-ONLY \\\n",
        "    --sparsity 0.5 0.6 \\\n",
        "    --epochs 10 \\\n",
        "    --num_samples 2048 \\\n",
        "    --num_eval_samples 1024 \\\n",
        "    --dataset_subset wikitext-103-raw-v1 \\\n",
        "    --dense_baseline \\\n",
        "    --seed 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWfyr-fQAm8D",
        "outputId": "d924d0ef-71f6-428a-e894-9f62f85d5b60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-08 07:36:08,151 - INFO - Model provider requested=auto effective=huggingface ollama_available=False ollama_model=llama3.2:1b\n",
            "2026-02-08 07:36:08,151 - INFO - Loading model: meta-llama/Llama-3.2-1B\n",
            "2026-02-08 07:36:12,774 - INFO - NumExpr defaulting to 12 threads.\n",
            "2026-02-08 07:36:13,398 - INFO - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:36:13,636 - INFO - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:36:13,876 - INFO - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:36:14,116 - INFO - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.2-1B/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:36:14,358 - INFO - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.2-1B/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:36:15,947 - INFO - HTTP Request: GET https://huggingface.co/api/models/meta-llama/Llama-3.2-1B \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:36:16,240 - INFO - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-02-08 07:36:16,913 - INFO - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
            "Loading weights: 100% 146/146 [00:00<00:00, 1517.32it/s, Materializing param=model.norm.weight]\n",
            "2026-02-08 07:36:17,340 - INFO - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 07:36:17,584 - INFO - HTTP Request: HEAD https://huggingface.co/meta-llama/Llama-3.2-1B/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 07:36:18,451 - INFO - Loading SPON checkpoint: results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-50_s0.50.pt\n",
            "2026-02-08 07:36:18,456 - INFO - Loaded 8 SPON biases\n",
            "2026-02-08 07:36:18,456 - INFO - Target modules inferred: ['down_proj']\n",
            "2026-02-08 07:36:18,456 - INFO - Layer indices inferred: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "2026-02-08 07:36:18,456 - INFO - \n",
            "=== Analysis 1: PCA Alignment ===\n",
            "2026-02-08 07:36:19,526 - INFO - SPON-PC alignment summary:\n",
            "2026-02-08 07:36:19,526 - INFO -   layer_0_down_proj: max_align=0.068, best_pc=8\n",
            "2026-02-08 07:36:19,526 - INFO -   layer_1_down_proj: max_align=0.040, best_pc=8\n",
            "2026-02-08 07:36:19,526 - INFO -   layer_2_down_proj: max_align=0.040, best_pc=8\n",
            "2026-02-08 07:36:19,526 - INFO -   layer_3_down_proj: max_align=0.048, best_pc=5\n",
            "2026-02-08 07:36:19,526 - INFO -   layer_4_down_proj: max_align=0.034, best_pc=6\n",
            "2026-02-08 07:36:19,526 - INFO -   layer_5_down_proj: max_align=0.060, best_pc=8\n",
            "2026-02-08 07:36:19,526 - INFO -   layer_6_down_proj: max_align=0.044, best_pc=6\n",
            "2026-02-08 07:36:19,527 - INFO -   layer_7_down_proj: max_align=0.034, best_pc=4\n",
            "2026-02-08 07:36:19,527 - INFO - \n",
            "=== Analysis 2: Category-specific Shifts ===\n",
            "2026-02-08 07:36:19,527 - INFO - Analyzing category: math\n",
            "2026-02-08 07:36:19,790 - INFO - Analyzing category: commonsense\n",
            "2026-02-08 07:36:20,022 - INFO - Analyzing category: coding\n",
            "2026-02-08 07:36:20,259 - INFO - Analyzing category: safety\n",
            "2026-02-08 07:36:20,493 - INFO - Analyzing category: factual\n",
            "2026-02-08 07:36:20,722 - INFO - L2 shift by category:\n",
            "2026-02-08 07:36:20,722 - INFO -   math: avg_l2=0.1787, avg_cka=0.9997\n",
            "2026-02-08 07:36:20,722 - INFO -   commonsense: avg_l2=0.1878, avg_cka=0.9996\n",
            "2026-02-08 07:36:20,722 - INFO -   coding: avg_l2=0.1826, avg_cka=0.9997\n",
            "2026-02-08 07:36:20,722 - INFO -   safety: avg_l2=0.1804, avg_cka=0.9996\n",
            "2026-02-08 07:36:20,722 - INFO -   factual: avg_l2=0.1842, avg_cka=0.9998\n",
            "2026-02-08 07:36:20,722 - INFO - \n",
            "=== Analysis 3: SPON Bias Statistics ===\n",
            "2026-02-08 07:36:20,726 - INFO - Bias statistics:\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_0_down_proj: norm=0.0362, std=0.0008\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_1_down_proj: norm=0.0342, std=0.0008\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_2_down_proj: norm=0.0349, std=0.0008\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_3_down_proj: norm=0.0405, std=0.0009\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_4_down_proj: norm=0.0443, std=0.0010\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_5_down_proj: norm=0.0452, std=0.0010\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_6_down_proj: norm=0.0509, std=0.0011\n",
            "2026-02-08 07:36:20,726 - INFO -   layer_7_down_proj: norm=0.0676, std=0.0015\n",
            "2026-02-08 07:36:20,726 - INFO - \n",
            "=== Analysis 4: Hidden-State Shift Quantification ===\n",
            "2026-02-08 07:36:21,768 - INFO -   layer_0_down_proj: TEAL shift=0.0374, SPON shift=0.0525, recovery=-40.5%\n",
            "2026-02-08 07:36:21,768 - INFO -   layer_1_down_proj: TEAL shift=0.0757, SPON shift=0.0889, recovery=-17.4%\n",
            "2026-02-08 07:36:21,768 - INFO -   layer_2_down_proj: TEAL shift=0.1177, SPON shift=0.1279, recovery=-8.7%\n",
            "2026-02-08 07:36:21,769 - INFO -   layer_3_down_proj: TEAL shift=0.1855, SPON shift=0.1963, recovery=-5.8%\n",
            "2026-02-08 07:36:21,769 - INFO -   layer_4_down_proj: TEAL shift=0.2236, SPON shift=0.2314, recovery=-3.5%\n",
            "2026-02-08 07:36:21,769 - INFO -   layer_5_down_proj: TEAL shift=0.2393, SPON shift=0.2480, recovery=-3.7%\n",
            "2026-02-08 07:36:21,769 - INFO -   layer_6_down_proj: TEAL shift=0.2461, SPON shift=0.2520, recovery=-2.4%\n",
            "2026-02-08 07:36:21,770 - INFO -   layer_7_down_proj: TEAL shift=0.2559, SPON shift=0.2656, recovery=-3.8%\n",
            "2026-02-08 07:36:21,770 - INFO -   ** Avg across layers: TEAL=0.1726, SPON=0.1828, recovery=-10.7%\n",
            "2026-02-08 07:36:21,770 - INFO - \n",
            "=== Analysis 5: Layer-wise Bias Norm Ranking ===\n",
            "2026-02-08 07:36:21,792 - INFO - Layers ranked by SPON bias L2 norm (most → least correction):\n",
            "2026-02-08 07:36:21,792 - INFO -   #1: layer_7_down_proj  norm=0.0676\n",
            "2026-02-08 07:36:21,792 - INFO -   #2: layer_6_down_proj  norm=0.0509\n",
            "2026-02-08 07:36:21,792 - INFO -   #3: layer_5_down_proj  norm=0.0452\n",
            "2026-02-08 07:36:21,792 - INFO -   #4: layer_4_down_proj  norm=0.0443\n",
            "2026-02-08 07:36:21,792 - INFO -   #5: layer_3_down_proj  norm=0.0405\n",
            "2026-02-08 07:36:21,792 - INFO -   #6: layer_0_down_proj  norm=0.0362\n",
            "2026-02-08 07:36:21,793 - INFO -   #7: layer_2_down_proj  norm=0.0349\n",
            "2026-02-08 07:36:21,793 - INFO -   #8: layer_1_down_proj  norm=0.0342\n",
            "2026-02-08 07:36:21,793 - INFO - \n",
            "=== Analysis 6: Cross-Config SPON Bias Comparison ===\n",
            "2026-02-08 07:36:21,835 - INFO -   layer_0_down_proj: cos_sim=0.9734, l2_diff=0.0083\n",
            "2026-02-08 07:36:21,835 - INFO -   layer_1_down_proj: cos_sim=0.9688, l2_diff=0.0085\n",
            "2026-02-08 07:36:21,836 - INFO -   layer_2_down_proj: cos_sim=0.9678, l2_diff=0.0088\n",
            "2026-02-08 07:36:21,836 - INFO -   layer_3_down_proj: cos_sim=0.9634, l2_diff=0.0109\n",
            "2026-02-08 07:36:21,836 - INFO -   layer_4_down_proj: cos_sim=0.9528, l2_diff=0.0135\n",
            "2026-02-08 07:36:21,837 - INFO -   layer_5_down_proj: cos_sim=0.9313, l2_diff=0.0165\n",
            "2026-02-08 07:36:21,837 - INFO -   layer_6_down_proj: cos_sim=0.9036, l2_diff=0.0222\n",
            "2026-02-08 07:36:21,837 - INFO -   layer_7_down_proj: cos_sim=0.8861, l2_diff=0.0339\n",
            "2026-02-08 07:36:21,837 - INFO -   ** Avg cosine similarity across shared layers: 0.9434\n",
            "2026-02-08 07:36:21,839 - INFO - \n",
            "Results saved to results/interpretability/interpretability_20260208_073608.json\n"
          ]
        }
      ],
      "source": [
        "# Use the best checkpoint from Exp1 (will be e.g. TOP-50 at 50% sparsity)\n",
        "# Adjust the path based on actual run timestamp\n",
        "\n",
        "CKPT_DIR=\"results/allocation_sweep/runs/$(ls -t results/allocation_sweep/runs/ | head -1)/checkpoints\"\n",
        "\n",
        "!python experiments/exp2_interpretability/run_interpretability.py \\\n",
        "    --model meta-llama/Llama-3.2-1B \\\n",
        "    --spon_checkpoint \"$CKPT_DIR/spon_TOP-50_s0.50.pt\" \\\n",
        "    --spon_checkpoint_b \"$CKPT_DIR/spon_UNIF-ALL_s0.50.pt\" \\\n",
        "    --sparsity 0.5 \\\n",
        "    --output_dir results/interpretability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "VPieu5SeLaTr",
        "outputId": "6d9be6f0-5a29-4a62-a6a8-52214f38175d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zipping results...\n",
            "  adding: content/spon-extension/results/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/aggregated/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/aggregated/summary.csv (deflated 54%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/aggregated/pareto.json (deflated 67%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/aggregated/latex_tables/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/aggregated/latex_tables/allocation_results.tex (deflated 53%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/analysis/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/analysis/statistics.json (deflated 83%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_064842/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_064842/checkpoints/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_064842/figures/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065455/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065455/checkpoints/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065455/figures/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065131/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065131/checkpoints/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065131/figures/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065236/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065236/checkpoints/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065236/figures/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/results.json (deflated 76%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/config.json (deflated 50%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-50_s0.60.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_UNIF-ALL_s0.50.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_ATTN-ONLY_s0.60.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_BOTTOM-50_s0.50.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_UNIF-ALL_s0.60.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_ATTN-ONLY_s0.50.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-75_s0.50.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-75_s0.60.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_BOTTOM-50_s0.60.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/checkpoints/spon_TOP-50_s0.50.pt (deflated 10%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/logs.json (deflated 57%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/figures/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/summary.json (deflated 74%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065528/metrics.csv (deflated 77%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065313/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065313/checkpoints/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/runs/run_20260208_065313/figures/ (stored 0%)\n",
            "  adding: content/spon-extension/results/allocation_sweep/metadata.json (deflated 36%)\n",
            "  adding: content/spon-extension/results/interpretability/ (stored 0%)\n",
            "  adding: content/spon-extension/results/interpretability/interpretability_20260208_073608.json (deflated 73%)\n",
            "Starting download...\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_e5f6d178-b7e7-4a56-a223-b3021d246b5b\", \"spon_results.zip\", 997465)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# path to your results\n",
        "results_path = '/content/spon-extension/results'\n",
        "\n",
        "if os.path.exists(results_path):\n",
        "    # Zip the entire results folder\n",
        "    print(\"Zipping results...\")\n",
        "    !zip -r /content/spon_results.zip {results_path}\n",
        "\n",
        "    # Download to your computer\n",
        "    print(\"Starting download...\")\n",
        "    files.download('/content/spon_results.zip')\n",
        "else:\n",
        "    print(f\"Error: Could not find results at {results_path}\")\n",
        "    print(\"Try running: !find /content -name results\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmWrLQ3VLssp",
        "outputId": "71c83e71-0812-4edc-9bc5-3fe63b2b80f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/spon-extension/results\n"
          ]
        }
      ],
      "source": [
        "!find /content -name results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjDk-X2hMAmq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
